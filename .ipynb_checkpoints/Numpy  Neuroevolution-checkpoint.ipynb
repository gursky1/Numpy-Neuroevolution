{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our activation function\n",
    "def relu(x):\n",
    "    return np.where(x>0,x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the softmax function\n",
    "def softmax(x):\n",
    "    x = np.exp(x - np.max(x))\n",
    "    return np.array(x / x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our random network generation function\n",
    "def create_network(n_units=(128,64),input_shape=784,output_shape=10):\n",
    "    # First we need to randomly initialize our weight and bias matrices\n",
    "    weights = []\n",
    "    biases = []\n",
    "    # Creating the weights for the hidden layers\n",
    "    for i in range(len(n_units)):\n",
    "        if i==0:\n",
    "            weights.append(np.random.uniform(-0.15,0.15,size=(input_shape,n_units[0])).astype('float32'))\n",
    "            biases.append(np.zeros(n_units[0]).astype('float32'))\n",
    "        else:\n",
    "            weights.append(np.random.uniform(-0.15,0.15,size=(n_units[i-1],n_units[i])).astype('float32'))\n",
    "            biases.append(np.zeros(n_units[i]).astype('float32'))\n",
    "    # Creating weights and biases for output layer\n",
    "    weights.append(np.random.uniform(-0.15,0.15,size=(n_units[-1],output_shape)).astype('float32'))\n",
    "    biases.append(np.zeros(output_shape))\n",
    "    return weights+biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to create our feed forward function\n",
    "def feed_forward(inputs, network):\n",
    "    # Dividing into the weights and biases\n",
    "    weights = network[0:len(network)//2]\n",
    "    biases = network[len(network)//2:]\n",
    "    # First we need to propogate inputs\n",
    "    a = relu((inputs@weights[0])+biases[0])\n",
    "    # Now we need to iterate through all of the remaining elements\n",
    "    for i in range(1,len(weights)):\n",
    "        a = relu((a@weights[i])+biases[i])\n",
    "    # Now we need to run softmax over the result\n",
    "    probs = np.apply_along_axis(softmax, axis=1, arr=a)\n",
    "    # Finally, return the max\n",
    "    return np.argmax(probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a better offspring generation function that selects neurons rather than random weights\n",
    "def offspring_network(weight_set1, weight_set2):\n",
    "    # First we need to create the child\n",
    "    child = [np.copy(i) for i in weight_set1]\n",
    "    # We need to select random neurons from each layer\n",
    "    # Axis 1 of W represents neurons\n",
    "    biases = [np.copy(i) for i in weight_set2[len(weight_set2)//2:]]\n",
    "    selected_biases = np.array([np.random.choice(range(i.shape[0]),size=i.shape[0]//2) for i in biases])\n",
    "    # Now to need to crossover the neurons in the child network\n",
    "    for i in range(int(np.floor(len(child)/2))):\n",
    "        for j in selected_biases[i]:\n",
    "            child[i][:,j] = weight_set2[i][:,j]\n",
    "    for i in range((len(child)//2)+1, len(child)):\n",
    "        for j in selected_biases[i-(len(child)//2)]:\n",
    "            child[i][j] = weight_set2[i][j]\n",
    "    return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to mutate a single network\n",
    "def mutate_layer(x, mutation_prob=0.1, type_probs=(0.8,0.1,0.1),shift_max=2.0,swap_max=2):\n",
    "    # Flattening our array\n",
    "    wts = x.flatten()\n",
    "    # Selecting which neurons get mutated\n",
    "    to_mutate = np.random.choice((0,1),size=wts.shape[0],p=(1-mutation_prob,mutation_prob))\n",
    "    to_mutate = np.array(np.where(to_mutate==1))\n",
    "    # Selecting which type of mutation to apply to each neuron\n",
    "    if len(np.where(to_mutate==1))>0:\n",
    "        mutation_type=np.random.choice(('shift','sign','swap'),size=to_mutate.shape[0],replace=True,p=type_probs)\n",
    "        # Performing shift mutations\n",
    "        to_shift = np.where(mutation_type=='shift')\n",
    "        wts[to_shift] = np.multiply(wts[to_shift],np.random.uniform(low=0.0,high=shift_max,size=len(to_shift)))\n",
    "        # Performing sign mutations\n",
    "        to_sign = np.where(mutation_type=='sign')\n",
    "        wts[to_sign] = wts[to_sign]*-1\n",
    "        # Performing swap mutations\n",
    "        to_swap = np.where(mutation_type=='swap')\n",
    "        wts[to_swap] = np.random.uniform(low=-1*swap_max,high=swap_max,size=len(to_swap))\n",
    "    return wts.reshape(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function that mutates an entire network\n",
    "def mutate_network(network, mutation_prob=0.1, type_probs=(0.8,0.1,0.1),shift_max=2.0,swap_max=2):\n",
    "    network = [mutate_layer(i,mutation_prob, type_probs,shift_max,swap_max) for i in network]\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our die-off function\n",
    "def die_off(pops, scores, rate=0.5):\n",
    "    # Sorting our populations first\n",
    "    sorted_inds = scores.argsort()\n",
    "    sorted_scores = -np.sort(-scores)\n",
    "    sorted_pops = pops[sorted_inds[::-1]]\n",
    "    # Killing off the weak\n",
    "    surviving_pop = sorted_pops[0:int(np.ceil(sorted_pops.shape[0]*(rate-1.)))]\n",
    "    surviving_scores = sorted_scores[0:int(np.ceil(sorted_pops.shape[0]*(rate-1.)))]\n",
    "    return surviving_pop, surviving_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for creating a child population based on fitness of parents\n",
    "def mate(pops, scores, num_children, fit_preference=2, mutation_prob=0.1, type_probs=(0.8,0.1,0.1),shift_max=2.0,swap_max=2):\n",
    "    # Creating standardized scores to use as mating probabilities\n",
    "    fitness = np.power(scores, fit_preference)\n",
    "    probs = fitness/fitness.sum()\n",
    "    # Selecting two sets of parents\n",
    "    parent1 = np.random.choice(a=range(pops.shape[0]), size=num_children, replace=True, p=probs)\n",
    "    parent2 = np.random.choice(a=range(pops.shape[0]), size=num_children, replace=True, p=probs)\n",
    "    parents = [(parent1[i], parent2[i]) for i in range(parent1.shape[0])]\n",
    "    # Next we need to create the list of the children\n",
    "    children = [offspring_network(pops[parents[i][0]], pops[parents[i][1]]) for i in range(len(parents))]\n",
    "    # Time to mutate the children\n",
    "    children = [mutate_network(i, mutation_prob, type_probs,shift_max,swap_max) for i in children]\n",
    "    children = np.array(children)\n",
    "    return np.concatenate([pops, children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our accuracy measure\n",
    "def accuracy(actual, preds):\n",
    "    return np.mean(np.where(actual==preds,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function for evaluating the fitness of our models\n",
    "def evaluate_fitness(networks, X, y):\n",
    "    # Creating a list comprehension of score evaluation\n",
    "    scores = np.array([accuracy(feed_forward(X,i), y) for i in networks])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST data\n",
    "X_train = np.genfromtxt('X_train.csv', delimiter=',')\n",
    "X_test = np.genfromtxt('X_test.csv', delimiter=',')\n",
    "y_train = np.genfromtxt('y_train.csv', delimiter=',')\n",
    "y_test = np.genfromtxt('y_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a function now to perform our genetic modeling\n",
    "# Setting the population size\n",
    "pop_size = 50\n",
    "\n",
    "# Setting the die-off rate\n",
    "die_off_rate = 0.25\n",
    "\n",
    "# Setting our fitness preference rate\n",
    "fitness_pref = 1.0\n",
    "\n",
    "# Setting the max number of iterations\n",
    "max_iter = 500\n",
    "\n",
    "# Setting mutation rates\n",
    "mutation_rate = 0.2\n",
    "type_probs = (0.8,0.1,0.1)\n",
    "shift_max = 3.0\n",
    "swap_max = 3\n",
    "\n",
    "# Setting caps for mutation\n",
    "mutation_rate_cap = 0.5\n",
    "\n",
    "# How often do we want to display progress?\n",
    "show_every = 1\n",
    "\n",
    "# How much should we increase mutation by when not improving?\n",
    "rate_increase = 0.0125\n",
    "current_mutation_rate = mutation_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 | Best Score: 0.2064 | Mutation Rate: 0.2\n",
      "Generation 2 | Best Score: 0.2064 | Mutation Rate: 0.213\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-6adbe08f161c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Evaluate fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Initializing the previous score variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-7f63f42f75b3>\u001b[0m in \u001b[0;36mevaluate_fitness\u001b[1;34m(networks, X, y)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Creating a list comprehension of score evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-7f63f42f75b3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Creating a list comprehension of score evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-a6faa95bef66>\u001b[0m in \u001b[0;36mfeed_forward\u001b[1;34m(inputs, network)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbiases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# First we need to propogate inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Now we need to iterate through all of the remaining elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creating our initial set of models\n",
    "models = np.array([create_network(n_units=(32,),input_shape=784,output_shape=10) for _ in range(pop_size)])\n",
    "\n",
    "# Starting our loop to train models\n",
    "for i in range(max_iter):\n",
    "    \n",
    "    # Evaluate fitness\n",
    "    scores = evaluate_fitness(models, X_train, y_train)\n",
    "    \n",
    "    # Initializing the previous score variable\n",
    "    if i==0:\n",
    "        previous_score = scores.max().round(4)\n",
    "    \n",
    "    # Cause die-off\n",
    "    models, scores = die_off(models, scores, die_off_rate)\n",
    "    \n",
    "    # Increasing mutation rate if necessary\n",
    "    if scores.max().round(4) == previous_score and i != 0:\n",
    "        current_mutation_rate += rate_increase\n",
    "    else:\n",
    "        current_mutation_rate = mutation_rate\n",
    "    # Checking if we have hit mutation caps\n",
    "    if current_mutation_rate > mutation_rate_cap:\n",
    "        current_mutation_rate = mutation_rate_cap\n",
    "    previous_score = scores.max().round(4)\n",
    "    \n",
    "    # Report best score\n",
    "    if (i+1)%show_every==0:\n",
    "        print('Generation',i+1,'| Best Score:',scores.max().round(4),'| Mutation Rate:',round(current_mutation_rate,3))\n",
    "    \n",
    "    # Create children\n",
    "    models = mate(pops=models,\n",
    "                  scores=scores,\n",
    "                  num_children=pop_size-models.shape[0],\n",
    "                  fit_preference=fitness_pref,\n",
    "                  mutation_prob=current_mutation_rate, \n",
    "                  type_probs=type_probs,\n",
    "                  shift_max=shift_max,\n",
    "                  swap_max=swap_max)\n",
    "\n",
    "# Done with training!\n",
    "print('Done with training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our GeneticMLP class\n",
    "class GeneticMLP():\n",
    "    def __init__(self, pop_size=100, die_off_rate=0.5,fitness_pref=1.0,generations=500,mutation_rate=0.2,\n",
    "                 type_probs=(0.8,0.1,0.1),shift_max=2.0, swap_max=2.0,mutation_rate_cap=0.4,verbose=False,print_every=1,\n",
    "                mutation_rate_increase=0.025):\n",
    "        self.pop_size = pop_size\n",
    "        self.die_off_rate = die_off_rate\n",
    "        self.fitness_pref = fitness_pref\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.type_probs = type_probs\n",
    "        self.shift_max = shift_max\n",
    "        self.swap_max = swap_max\n",
    "        self.mutation_rate_cap = mutation_rate_cap\n",
    "        self.verbose = verbose\n",
    "        self.print_every = print_every\n",
    "        self.mutation_rate_increase = mutation_rate_increase\n",
    "        return self\n",
    "\n",
    "    def fit(X, y):\n",
    "        \n",
    "    def predict(X):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test to make sure the feed forward command is working using keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Creating our network\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(784,),activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,epochs=5)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing model weights\n",
    "def convert_to_numpy(x):\n",
    "    weights = x[::2]\n",
    "    biases = x[1::2]\n",
    "    return np.array(weights+biases)\n",
    "keras_model = convert_to_numpy(model.get_weights())\n",
    "print(keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running it though our propgation function\n",
    "print(feed_forward(X_train, keras_model))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the network offspring function\n",
    "net1 = create_network(n_units=(32,),input_shape=784,output_shape=10)\n",
    "net2 = create_network(n_units=(32,),input_shape=784,output_shape=10)\n",
    "print(net1[0][0,0:6])\n",
    "#print(net2)\n",
    "child = offspring_network(net1,net2)\n",
    "print(net1[0][0,0:6])\n",
    "#print(net2)\n",
    "#print(child)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
