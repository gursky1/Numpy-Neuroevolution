{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our activation function\n",
    "def relu(x):\n",
    "    return np.where(x>0,x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the softmax function\n",
    "def softmax(x):\n",
    "    x = np.exp(x - np.max(x))\n",
    "    return np.array(x / x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our random network generation function\n",
    "def create_network(n_units=(128,64),input_shape=784,output_shape=10):\n",
    "    # First we need to randomly initialize our weight and bias matrices\n",
    "    weights = []\n",
    "    biases = []\n",
    "    # Creating the weights for the hidden layers\n",
    "    for i in range(len(n_units)):\n",
    "        if i==0:\n",
    "            weights.append(np.random.uniform(-0.15,0.15,size=(input_shape,n_units[0])).astype('float32'))\n",
    "            biases.append(np.zeros(n_units[0]).astype('float32'))\n",
    "        else:\n",
    "            weights.append(np.random.uniform(-0.15,0.15,size=(n_units[i-1],n_units[i])).astype('float32'))\n",
    "            biases.append(np.zeros(n_units[i]).astype('float32'))\n",
    "    # Creating weights and biases for output layer\n",
    "    weights.append(np.random.uniform(-0.15,0.15,size=(n_units[-1],output_shape)).astype('float32'))\n",
    "    biases.append(np.zeros(output_shape))\n",
    "    return weights+biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to create our feed forward function\n",
    "def feed_forward(inputs, network):\n",
    "    # Dividing into the weights and biases\n",
    "    weights = network[0:len(network)//2]\n",
    "    biases = network[len(network)//2:]\n",
    "    # First we need to propogate inputs\n",
    "    a = relu((inputs@weights[0])+biases[0])\n",
    "    # Now we need to iterate through all of the remaining elements\n",
    "    for i in range(1,len(weights)):\n",
    "        a = relu((a@weights[i])+biases[i])\n",
    "    # Now we need to run softmax over the result\n",
    "    probs = np.apply_along_axis(softmax, axis=1, arr=a)\n",
    "    # Finally, return the max\n",
    "    return np.argmax(probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to create an offspring array\n",
    "def offspring_array(x1, x2):\n",
    "    # We need to save the final shape\n",
    "    shape = x1.shape\n",
    "    # We need to select half of x1 indices randomly\n",
    "    child = x1.flatten()\n",
    "    child[np.random.choice(range(child.shape[0]),size=int(np.ceil(child.shape[0]/2)))] = 0\n",
    "    # Now we need to fill in the zero values\n",
    "    child[np.where(child==0)[0]] = x2.flatten()[np.where(child==0)[0]]\n",
    "    return child.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try writing a simple offspring generator\n",
    "def create_offspring(weight_set1, weight_set2):\n",
    "    # First we need to iterate through and create offspring layer weights\n",
    "    offspring = [offspring_array(weight_set1[i],weight_set2[i]) for i in range(weight_set1.shape[0])]\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets define some of our base mutation functions\n",
    "def weight_shift(x, prob=0.1, var=0.1):\n",
    "    # Flattening out our array\n",
    "    wts = x.flatten()\n",
    "    # Selecting neurons to mutate\n",
    "    to_mutate = np.random.choice(range(wts.shape[0]),size=int(np.ceil(prob*wts.shape[0])))\n",
    "    # Applying mutation noise\n",
    "    wts[to_mutate] = wts[to_mutate]+np.random.normal(0,var)\n",
    "    return wts.reshape(x.shape)\n",
    "\n",
    "def weight_random(x, prob=0.1, min_val = -4, max_val=4):\n",
    "    # Flattening out our array\n",
    "    wts = x.flatten()\n",
    "    # Selecting neurons to mutate\n",
    "    to_mutate = np.random.choice(range(wts.shape[0]),size=int(np.ceil(prob*wts.shape[0])))\n",
    "    # Applying mutation noise\n",
    "    wts[to_mutate] = np.random.uniform(low=min_val, high=max_val, size=len(to_mutate))\n",
    "    return wts.reshape(x.shape)\n",
    "\n",
    "# Mutation functions for networks\n",
    "def mutate_weight_shift(x, prob=0.1, var=0.5):\n",
    "    # Iterating over all layers applying mutations\n",
    "    x = [weight_shift(x[i], prob, var) for i in range(len(x))]\n",
    "    return x\n",
    "\n",
    "def mutate_weight_random(x, prob=0.1, min_val=-4, max_val=4):\n",
    "    # Iterating over all layers applying mutations\n",
    "    x = [weight_random(x[i],prob,min_val,max_val) for i in range(len(x))]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our die-off function\n",
    "def die_off(pops, scores, rate=0.5):\n",
    "    # Sorting our populations first\n",
    "    sorted_inds = scores.argsort()\n",
    "    sorted_scores = -np.sort(-scores)\n",
    "    sorted_pops = pops[sorted_inds[::-1]]\n",
    "    # Killing off the weak\n",
    "    surviving_pop = sorted_pops[0:int(np.ceil(sorted_pops.shape[0]*(rate-1.)))]\n",
    "    surviving_scores = sorted_scores[0:int(np.ceil(sorted_pops.shape[0]*(rate-1.)))]\n",
    "    return surviving_pop, surviving_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for creating a child population based on fitness of parents\n",
    "def mate(pops, scores, num_children, shift_prob=0.1, random_prob=0.1, var=0.1, min_val=-4, max_val=4, fit_preference=2):\n",
    "    # Creating standardized scores to use as mating probabilities\n",
    "    fitness = np.power(scores, fit_preference)\n",
    "    probs = fitness/fitness.sum()\n",
    "    # Selecting two sets of parents\n",
    "    parent1 = np.random.choice(a=range(pops.shape[0]), size=num_children, replace=True, p=probs)\n",
    "    parent2 = np.random.choice(a=range(pops.shape[0]), size=num_children, replace=True, p=probs)\n",
    "    parents = [(parent1[i], parent2[i]) for i in range(parent1.shape[0])]\n",
    "    # Next we need to create the list of the children\n",
    "    children = [create_offspring(pops[parents[i][0]], pops[parents[i][1]]) for i in range(len(parents))]\n",
    "    # Time to mutate the children\n",
    "    children = [mutate_weight_shift(i, shift_prob, var) for i in children]\n",
    "    children = [mutate_weight_random(i, random_prob, min_val, max_val) for i in children]\n",
    "    children = np.array(children)\n",
    "    return np.concatenate([pops, children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our accuracy measure\n",
    "def accuracy(actual, preds):\n",
    "    return np.mean(np.where(actual==preds,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function for evaluating the fitness of our models\n",
    "def evaluate_fitness(networks, X, y):\n",
    "    # Creating a list comprehension of score evaluation\n",
    "    scores = np.array([accuracy(feed_forward(X,i), y) for i in networks])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST data\n",
    "X_train = np.genfromtxt('X_train.csv', delimiter=',')\n",
    "X_test = np.genfromtxt('X_test.csv', delimiter=',')\n",
    "y_train = np.genfromtxt('y_train.csv', delimiter=',')\n",
    "y_test = np.genfromtxt('y_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 | Best Score: 0.1709\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-b3500455909a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Evaluate fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# Report best score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-7f63f42f75b3>\u001b[0m in \u001b[0;36mevaluate_fitness\u001b[1;34m(networks, X, y)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Creating a list comprehension of score evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-7f63f42f75b3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Creating a list comprehension of score evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-8951f852f961>\u001b[0m in \u001b[0;36mfeed_forward\u001b[1;34m(inputs, network)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#a = relu(np.dot(weights[i],a)+biases[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Now we need to run softmax over the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Finally, return the max\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[0mbuff\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mbuff\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-664ab805859d>\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Defining the softmax function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[0;32m   2503\u001b[0m     \"\"\"\n\u001b[0;32m   2504\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out, keepdims=keepdims,\n\u001b[1;32m-> 2505\u001b[1;33m                           initial=initial)\n\u001b[0m\u001b[0;32m   2506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lets create a function now to perform our genetic modeling\n",
    "# Setting the population size\n",
    "pop_size = 500\n",
    "\n",
    "# Setting the die-off rate\n",
    "die_off_rate=0.5\n",
    "\n",
    "# Setting our fitness preference rate\n",
    "fitness_pref = 1.5\n",
    "\n",
    "# Creating our initial set of models\n",
    "models = np.array([create_network(n_units=(64,),input_shape=784,output_shape=10) for _ in range(pop_size)])\n",
    "\n",
    "# Setting the max number of iterations\n",
    "max_iter = 100\n",
    "\n",
    "# Setting mutation rates\n",
    "shift_mutate = 0.5\n",
    "shift_var = 0.3\n",
    "random_mutate=0.2\n",
    "\n",
    "# Starting our loop to train models\n",
    "for i in range(max_iter):\n",
    "    # Evaluate fitness\n",
    "    scores = evaluate_fitness(models, X_train, y_train)\n",
    "    \n",
    "    # Report best score\n",
    "    print('Generation',i+1,'| Best Score:',scores.max().round(4))\n",
    "    \n",
    "    # Cause die-off\n",
    "    models, scores = die_off(models, scores, die_off_rate)\n",
    "    \n",
    "    # Create children\n",
    "    models = mate(pops=models, \n",
    "                  scores=scores, \n",
    "                  num_children=pop_size-models.shape[0], \n",
    "                  shift_prob=shift_mutate, \n",
    "                  random_prob=random_mutate, \n",
    "                  var=shift_var, \n",
    "                  fit_preference=fitness_pref)\n",
    "    \n",
    "# Done with training!\n",
    "print('Done with training!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
